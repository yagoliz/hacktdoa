{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and define the header\n",
    "filename = '../data/recordings/s2_5_sf10.raw'\n",
    "file_size = os.path.getsize(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the header\n",
    "header_t = np.dtype([('start_time', np.uint64),('center_freq', np.double),('gain', np.double),('sample_freq', np.double)])\n",
    "header = np.fromfile(filename, dtype=header_t, count=1, sep='', offset=0)\n",
    "header_size = header.itemsize\n",
    "\n",
    "# Saving with our beloved variable names\n",
    "start_time = header[0][0]\n",
    "fc = header[0][1]\n",
    "gain = header[0][2]\n",
    "bw = header[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the approximate number of chunks by reading the first\n",
    "bytes64 = 8 # number of bytes in a 64 bit type\n",
    "chunk_length = np.fromfile(filename, dtype=np.uint64, count=1, offset=header_size + 16)\n",
    "chunk_size = 3 * bytes64 + 2 * (bytes64//2) * chunk_length\n",
    "\n",
    "nchunks = (file_size - header_size) // chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve arrays\n",
    "seconds = np.empty(nchunks, dtype=int)\n",
    "nanoseconds = np.empty(nchunks, dtype=np.float64)\n",
    "samples = np.empty(((chunk_length * nchunks)[0],2), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = header_size\n",
    "\n",
    "i = 0\n",
    "while offset < file_size:\n",
    "    # subheaders of the chunk\n",
    "    sec   = np.fromfile(filename, dtype=np.uint64 , count=1, offset=offset)\n",
    "    nsec  = np.fromfile(filename, dtype=np.float64, count=1, offset=offset+bytes64)\n",
    "    nsamp = np.fromfile(filename, dtype=np.uint64 , count=1, offset=offset+2*bytes64)\n",
    "\n",
    "    # flat array with the i/q samples of the chunk\n",
    "    samps_flat = np.fromfile(filename, dtype=np.float32, count=int(nsamp*2), offset=offset+3*bytes64)\n",
    "    samps_i = samps_flat[0::2]\n",
    "    samps_q = samps_flat[1::2]\n",
    "\n",
    "    # store our precious data on our result vector\n",
    "    seconds[i] = sec\n",
    "    nanoseconds[i] = nsec\n",
    "    samples[int(i*nsamp):int((i+1)*nsamp),0] = samps_i\n",
    "    samples[int(i*nsamp):int((i+1)*nsamp),1] = samps_q\n",
    "\n",
    "    i += 1\n",
    "    offset += int(3 * bytes64 + 2 * (bytes64//2) * nsamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('test.mat', {'bw': bw, 'fc': fc, 'gain': gain, 'start_time': start_time, 'chunk_length': chunk_length, 'seconds': seconds, 'nanoseconds': nanoseconds, 'samples': samples})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dir = '../data/receivers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 's2_5_sf10.raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Let's define the header\u001b[39;00m\n\u001b[1;32m      5\u001b[0m header_t \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype([(\u001b[39m'\u001b[39m\u001b[39mstart_time\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39muint64),(\u001b[39m'\u001b[39m\u001b[39mcenter_freq\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mdouble),(\u001b[39m'\u001b[39m\u001b[39mgain\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mdouble),(\u001b[39m'\u001b[39m\u001b[39msample_freq\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mdouble)])\n\u001b[0;32m----> 6\u001b[0m header \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfromfile(file\u001b[39m.\u001b[39mname, dtype\u001b[39m=\u001b[39mheader_t, count\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, offset\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m header_size \u001b[39m=\u001b[39m header\u001b[39m.\u001b[39mitemsize\n\u001b[1;32m      9\u001b[0m \u001b[39m# Saving with our beloved variable names\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 's2_5_sf10.raw'"
     ]
    }
   ],
   "source": [
    "for file in os.scandir(scan_dir):\n",
    "    file_name = file.name.split('.')[0]\n",
    "    full_path = os.path.join(scan_dir,file.name)\n",
    "\n",
    "    # Let's define the header\n",
    "    header_t = np.dtype([('start_time', np.uint64),('center_freq', np.double),('gain', np.double),('sample_freq', np.double)])\n",
    "    header = np.fromfile(full_path, dtype=header_t, count=1, sep='', offset=0)\n",
    "    header_size = header.itemsize\n",
    "\n",
    "    # Saving with our beloved variable names\n",
    "    start_time = header[0][0]\n",
    "    fc = header[0][1]\n",
    "    gain = header[0][2]\n",
    "    bw = header[0][3]\n",
    "\n",
    "    # Get the approximate number of chunks by reading the first\n",
    "    bytes64 = 8 # number of bytes in a 64 bit type\n",
    "    chunk_length = np.fromfile(full_path, dtype=np.uint64, count=1, offset=header_size + 16)\n",
    "    chunk_size = 3 * bytes64 + 2 * (bytes64//2) * chunk_length\n",
    "\n",
    "    nchunks = (file_size - header_size) // chunk_size\n",
    "\n",
    "    # Reserve arrays\n",
    "    seconds = np.empty(nchunks, dtype=int)\n",
    "    nanoseconds = np.empty(nchunks, dtype=np.float64)\n",
    "    samples = np.empty(((chunk_length * nchunks)[0],2), dtype=np.float64)\n",
    "\n",
    "    # main loop\n",
    "    offset = header_size\n",
    "\n",
    "    i = 0\n",
    "    while offset < file_size:\n",
    "        # subheaders of the chunk\n",
    "        sec   = np.fromfile(full_path, dtype=np.uint64 , count=1, offset=offset)\n",
    "        nsec  = np.fromfile(full_path, dtype=np.float64, count=1, offset=offset+bytes64)\n",
    "        nsamp = np.fromfile(full_path, dtype=np.uint64 , count=1, offset=offset+2*bytes64)\n",
    "\n",
    "        # flat array with the i/q samples of the chunk\n",
    "        samps_flat = np.fromfile(full_path, dtype=np.float32, count=int(nsamp*2), offset=offset+3*bytes64)\n",
    "        samps_i = samps_flat[0::2]\n",
    "        samps_q = samps_flat[1::2]\n",
    "\n",
    "        # store our precious data on our result vector\n",
    "        seconds[i] = sec\n",
    "        nanoseconds[i] = nsec\n",
    "        samples[int(i*nsamp):int((i+1)*nsamp),0] = samps_i\n",
    "        samples[int(i*nsamp):int((i+1)*nsamp),1] = samps_q\n",
    "\n",
    "        i += 1\n",
    "        offset += int(3 * bytes64 + 2 * (bytes64//2) * nsamp)\n",
    "    \n",
    "    # save to the cursed .mat format\n",
    "    scipy.io.savemat(f'../data/matfiles/{file_name}.mat', {'bw': bw, 'fc': fc, 'gain': gain, 'start_time': start_time, 'chunk_length': chunk_length, 'seconds': seconds, 'nanoseconds': nanoseconds, 'samples': samples})\n",
    "    print(f'Saved file: ../data/matfiles/{file_name}.mat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('hacktdoa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f3d3a7dc257d3606aacb576584d6f288cbb76a346a8fdae608beb59d0cdf71b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
